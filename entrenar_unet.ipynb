{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3ce8d76",
   "metadata": {},
   "source": [
    "### Creación de gpkg de division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0929a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Píxeles válidos totales: 588882000\n",
      "Val   asignado: 117781300 (20.0%)\n",
      "Test asignado: 70667800 (12.0%)\n",
      "Train: 400432900\n",
      "Píxeles válidos totales: 591685632\n",
      "Val   asignado: 141992813 (24.0%)\n",
      "Test asignado: 70996458 (12.0%)\n",
      "Train: 378696361\n"
     ]
    }
   ],
   "source": [
    "from utils_pre_procesamiento import generar_tiles_spatial_split\n",
    "\n",
    "tif_sierra = r\"\"\n",
    "out_dir_sierra = r\"\"\n",
    "\n",
    "tif_selva = r\"\"\n",
    "out_dir_selva = r\"\"\n",
    "\n",
    "generar_tiles_spatial_split(tif_sierra, out_dir = out_dir_sierra)\n",
    "generar_tiles_spatial_split(tif_selva, out_dir = out_dir_selva)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5102f70",
   "metadata": {},
   "source": [
    "### Creacion de parches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106d62fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leyendo raster entero para calcular percentiles para posterior normalización de parches\n",
      "Cargando raster...\n",
      "Cargando geometrías...\n",
      "Geometria de : Casas\n",
      "Geometria de : Caminos\n",
      "Geometria de : Area fuera de interes\n",
      "Cargando tiles...\n",
      "\n",
      "Procesando tile 0 → train\n",
      "\n",
      "Procesando tile 1 → train\n",
      "\n",
      "Procesando tile 2 → val\n",
      "\n",
      "Procesando tile 3 → train\n",
      "\n",
      "Procesando tile 4 → train\n",
      "\n",
      "Procesando tile 5 → train\n",
      "\n",
      "Procesando tile 6 → train\n",
      "\n",
      "Procesando tile 7 → train\n",
      "\n",
      "Procesando tile 8 → test\n",
      "\n",
      "Procesando tile 9 → train\n",
      "\n",
      "Procesando tile 10 → val\n",
      "\n",
      "Procesando tile 11 → train\n",
      "\n",
      "Procesando tile 12 → val\n",
      "\n",
      "Procesando tile 13 → train\n",
      "\n",
      "Procesando tile 14 → train\n",
      "\n",
      "Procesando tile 15 → train\n",
      "\n",
      "Procesando tile 16 → train\n",
      "\n",
      "Procesando tile 17 → train\n",
      "\n",
      "Procesando tile 18 → test\n",
      "\n",
      "Procesando tile 19 → train\n",
      "\n",
      "Procesando tile 20 → val\n",
      "\n",
      "Procesando tile 21 → test\n",
      "\n",
      "Procesando tile 22 → val\n",
      "\n",
      "Procesando tile 23 → train\n",
      "\n",
      "Procesando tile 24 → train\n",
      "\n",
      " LISTO: Dataset generado correctamente.\n",
      "Total de parches generados: 002705_006024\n",
      "Leyendo raster entero para calcular percentiles para posterior normalización de parches\n",
      "Cargando raster...\n",
      "Cargando geometrías...\n",
      "Geometria de : Casas\n",
      "Geometria de : Caminos\n",
      "Cargando tiles...\n",
      "\n",
      "Procesando tile 0 → val\n",
      "\n",
      "Procesando tile 1 → test\n",
      "\n",
      "Procesando tile 2 → val\n",
      "\n",
      "Procesando tile 3 → train\n",
      "\n",
      "Procesando tile 4 → val\n",
      "\n",
      "Procesando tile 5 → train\n",
      "\n",
      "Procesando tile 6 → train\n",
      "\n",
      "Procesando tile 7 → train\n",
      "\n",
      "Procesando tile 8 → train\n",
      "\n",
      "Procesando tile 9 → train\n",
      "\n",
      "Procesando tile 10 → test\n",
      "\n",
      "Procesando tile 11 → val\n",
      "\n",
      "Procesando tile 12 → train\n",
      "\n",
      "Procesando tile 13 → train\n",
      "\n",
      "Procesando tile 14 → train\n",
      "\n",
      "Procesando tile 15 → train\n",
      "\n",
      "Procesando tile 16 → train\n",
      "\n",
      "Procesando tile 17 → test\n",
      "\n",
      "Procesando tile 18 → train\n",
      "\n",
      "Procesando tile 19 → val\n",
      "\n",
      "Procesando tile 20 → val\n",
      "\n",
      "Procesando tile 21 → train\n",
      "\n",
      "Procesando tile 22 → train\n",
      "\n",
      "Procesando tile 23 → train\n",
      "\n",
      "Procesando tile 24 → train\n",
      "\n",
      " LISTO: Dataset generado correctamente.\n",
      "Total de parches generados: 010438_002418\n"
     ]
    }
   ],
   "source": [
    "from raster_to_tile import data_split\n",
    "\n",
    "tif_selva = r\"\"\n",
    "tif_sierra = r\"\"\n",
    "\n",
    "mask_casas_selva_path = r\"\"\n",
    "mask_casas_sierra_path = r\"\"\n",
    "\n",
    "mask_caminos_selva_path = r\"\"\n",
    "mask_caminos_sierra_path = r\"\"\n",
    "\n",
    "gpkg_division_selva_tile = r\"\"\n",
    "gpkg_division_sierra_tile = r\"\"\n",
    "\n",
    "dataset_general_out = r\"\"\n",
    "\n",
    "### Area Excluida\n",
    "gpkg_area_ciudad = r\"\"\n",
    "\n",
    "#Sierra\n",
    "data_split(tif_sierra, mask_casas_sierra_path, mask_caminos_sierra_path, gpkg_division_sierra_tile, dataset_general_out, gpkg_area_excluida_path=gpkg_area_ciudad)\n",
    "#Selva\n",
    "data_split(tif_selva, mask_casas_selva_path, mask_caminos_selva_path, gpkg_division_selva_tile, dataset_general_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5762ec",
   "metadata": {},
   "source": [
    "### Verificar GPU disponible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba486f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(\"TF version:\", tf.__version__)\n",
    "print(\"Built with CUDA:\", tf.test.is_built_with_cuda())\n",
    "print(\"GPUs:\", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d6a780",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils2 import split_dataset\n",
    "\n",
    "(train_imgs, train_masks, val_imgs, val_masks, test_imgs, test_masks) = split_dataset(carpeta=dataset_general_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7bab74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from TiffDataGeneratorAugmentedUnet import TIFFDataGeneratorAug\n",
    "\n",
    "# Generadores\n",
    "train_gen = TIFFDataGeneratorAug(train_imgs, train_masks, normalize='imagenet',batch_size=1, n_channels=3, augment=True)#<--- canales\n",
    "val_gen = TIFFDataGeneratorAug(val_imgs, val_masks, normalize='imagenet', batch_size=1, shuffle=False, n_channels=3, augment=False)#<--- canales\n",
    "test_gen = TIFFDataGeneratorAug(test_imgs, test_masks, normalize='imagenet', batch_size=1, shuffle=False, n_channels=3, augment=False)#<--- canales\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d86c3203",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"SM_FRAMEWORK\"] = \"tf.keras\"\n",
    "\n",
    "from tensorflow import keras\n",
    "import segmentation_models as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3bdeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "import configuraciones as cfg\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "BACKBONE = 'resnet34'#efficientnetb0 tmb puede ser (buena con imag satelitales)\n",
    "model = sm.Unet(\n",
    "    backbone_name=BACKBONE,\n",
    "    encoder_weights='imagenet',\n",
    "    classes=3,\n",
    "    activation='softmax'\n",
    "    #input_shape=(512, 512, 4)\n",
    ")\n",
    "\n",
    "# Definir nombres de clases\n",
    "class_names = ['background', 'road', 'building']\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(1e-4),\n",
    "    loss=cfg.masked_sparse_cce,\n",
    "    metrics=[\n",
    "        cfg.MaskedSparseCategoricalAccuracy(num_classes=3, class_names=class_names, name='acc'),\n",
    "        cfg.MaskedIoUPerClass(num_classes=3, class_names=class_names, name='miou')\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d6dd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',      # métrica que se evalúa\n",
    "    mode='min',\n",
    "    patience=10,\n",
    "    restore_best_weights=True,\n",
    "    verbose= 1\n",
    ")\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    r\"checkpoint.keras\",         # ruta del archivo\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau( # reduccion lr auto\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=5,\n",
    "    min_lr=1e-7,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80cc860",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=100,\n",
    "    verbose=1,\n",
    "    callbacks=[early_stop, checkpoint, reduce_lr, cfg.PrintMetricsPerClass()]\n",
    ")\n",
    "print(\"Epochs realizadas:\", len(history.history['loss']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255a90fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Después del entrenamiento, obtener IoU por clase\n",
    "iou_metric = model.metrics[-1]  # Última métrica\n",
    "iou_per_class = iou_metric.get_iou_per_class()\n",
    "\n",
    "print(\"\\nIoU por clase:\")\n",
    "for class_name, iou_value in iou_per_class.items():\n",
    "    print(f\"  {class_name}: {iou_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3f6419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final model\n",
    "model.save(\"model_final.keras\")\n",
    "\n",
    "# Evaluate on train set\n",
    "print(\"\\n=== Evaluación en test set ===\")\n",
    "train_results = model.evaluate(train_gen, verbose=1)\n",
    "print(f\"Train Loss: {train_results[0]:.4f}\")\n",
    "print(f\"Train Masked Accuracy: {train_results[1]:.4f}\")\n",
    "print(f\"Train Masked Mean IoU: {train_results[2]:.4f}\")\n",
    "# Evaluate on test set\n",
    "print(\"\\n=== Evaluación en val set ===\")\n",
    "val_results = model.evaluate(val_gen, verbose=1)\n",
    "print(f\"Val Loss: {val_results[0]:.4f}\")\n",
    "print(f\"Val Masked Accuracy: {val_results[1]:.4f}\")\n",
    "print(f\"Val Masked Mean IoU: {val_results[2]:.4f}\")\n",
    "# Evaluate on test set\n",
    "print(\"\\n=== Evaluación en test set ===\")\n",
    "test_results = model.evaluate(test_gen, verbose=1)\n",
    "print(f\"Test Loss: {test_results[0]:.4f}\")\n",
    "print(f\"Test Masked Accuracy: {test_results[1]:.4f}\")\n",
    "print(f\"Test Masked Mean IoU: {test_results[2]:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
