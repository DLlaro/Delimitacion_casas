{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106d62fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from raster_to_tile import data_split\n",
    "\n",
    "tif_selva = r\"D:\\Shapefiles\\PI\\CO_2512022106159\\VOL_PER1_ORT_001_010438\\IMG_PER1_ORT_PMS_010438\\IMG_PER1_20230922151914_ORT_PMS_010438.TIF\"\n",
    "tif_sierra = r\"D:\\Shapefiles\\PI\\CO_2510221339013\\VOL_PER1_ORT_001_002705\\IMG_PER1_ORT_PMS_002705\\IMG_PER1_20210706153514_ORT_PMS_002705.TIF\"\n",
    "\n",
    "mask_casas_selva_path = r\"D:\\Diciembre\\Entrenamiento\\training_road_model\\CapasSelva\\buildings_32718_selva.gpkg\"\n",
    "mask_casas_sierra_path = r\"D:\\Diciembre\\Entrenamiento\\training_road_model\\CapasSierra\\buildings_32717_sierra.gpkg\"\n",
    "\n",
    "mask_caminos_selva_path = r\"D:\\Diciembre\\Entrenamiento\\training_road_model\\CapasSelva\\capa_carreteras_selva.gpkg\"\n",
    "mask_caminos_sierra_path = r\"D:\\Diciembre\\Entrenamiento\\training_road_model\\CapasSierra\\\\capa_carreteras_sierra.gpkg\"\n",
    "\n",
    "gpkg_division_selva_tile = r\"D:\\Diciembre\\Entrenamiento\\training_road_model\\CapasSelva\\division_en_tile_selva.gpkg\"\n",
    "gpkg_division_sierra_tile = r\"D:\\Diciembre\\Entrenamiento\\training_road_model\\CapasSierra\\division_en_tile_sierra.gpkg\"\n",
    "\n",
    "dataset_selva_path = r\"D:\\Diciembre\\Entrenamiento\\training_road_model\\DatasetSelvaMulticlase\"\n",
    "dataset_sierra_path = r\"D:\\Diciembre\\Entrenamiento\\training_road_model\\DatasetSierraMulticlase\"\n",
    "\n",
    "### Area Excluida\n",
    "gpkg_area_ciudad = r\"D:\\Diciembre\\Entrenamiento\\training_road_model\\CapasSierra\\area_excluida_sierra.gpkg\"\n",
    "\n",
    "data_split(tif_sierra, mask_casas_sierra_path, mask_caminos_sierra_path, gpkg_division_sierra_tile, dataset_sierra_path, gpkg_area_excluida_path=gpkg_area_ciudad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba486f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(\"TF version:\", tf.__version__)\n",
    "print(\"Built with CUDA:\", tf.test.is_built_with_cuda())\n",
    "print(\"GPUs:\", tf.config.list_physical_devices('GPU'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d3d6a780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Divisi√≥n correcta sin errores de archivos.\n",
      "--------------------------------------------------\n",
      "TRAIN     ‚Üí im√°genes: 4117 | m√°scaras: 4117\n",
      "VALIDATION ‚Üí im√°genes: 938 | m√°scaras: 938\n",
      "TEST      ‚Üí im√°genes: 969 | m√°scaras: 969\n",
      "--------------------------------------------------\n",
      "TOTAL IMGS: 6024\n",
      "TOTAL MASKS: 6024\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from utils2 import split_dataset\n",
    "dataset_path = r\"D:\\Diciembre\\Entrenamiento\\training_road_model\\DatasetSierraMulticlase\"\n",
    "\n",
    "(train_imgs, train_masks, val_imgs, val_masks, test_imgs, test_masks) = split_dataset(carpeta=dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7bab74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from TiffDataGeneratorAugmentedUnet import TIFFDataGeneratorAug\n",
    "\n",
    "# Generadores\n",
    "train_gen = TIFFDataGeneratorAug(train_imgs, train_masks, normalize='imagenet',batch_size=1, n_channels=3, augment=True)#<--- canales\n",
    "val_gen = TIFFDataGeneratorAug(val_imgs, val_masks, normalize='imagenet', batch_size=1, shuffle=False, n_channels=3, augment=False)#<--- canales\n",
    "test_gen = TIFFDataGeneratorAug(test_imgs, test_masks, normalize='imagenet', batch_size=1, shuffle=False, n_channels=3, augment=False)#<--- canales\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d86c3203",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"SM_FRAMEWORK\"] = \"tf.keras\"\n",
    "\n",
    "from tensorflow import keras\n",
    "import segmentation_models as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e3e3d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_sparse_cce(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Sparse categorical crossentropy que ignora p√≠xeles con label 255\n",
    "    \"\"\"\n",
    "    y_true = tf.squeeze(y_true, axis=-1)  # (B,H,W)\n",
    "    y_true = tf.cast(y_true, tf.int32)\n",
    "    # Crear m√°scara para p√≠xeles v√°lidos\n",
    "    mask = tf.not_equal(y_true, 255)\n",
    "    mask = tf.cast(mask, tf.float32)\n",
    "    \n",
    "    # Reemplazar 255 con 0 para evitar errores\n",
    "    y_true_safe = tf.where(mask > 0, y_true, tf.zeros_like(y_true))\n",
    "    \n",
    "    # Calcular loss por p√≠xel\n",
    "    loss = tf.keras.losses.sparse_categorical_crossentropy(\n",
    "        y_true_safe, y_pred, from_logits=False\n",
    "    )\n",
    "    \n",
    "    # Aplicar m√°scara y promediar solo sobre p√≠xeles v√°lidos\n",
    "    loss = loss * mask\n",
    "    \n",
    "    # Evitar divisi√≥n por cero\n",
    "    num_valid = tf.maximum(tf.reduce_sum(mask), 1.0)\n",
    "    \n",
    "    return tf.reduce_sum(loss) / num_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fcb6b3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedIoUPerClass(tf.keras.metrics.Metric):\n",
    "    def __init__(self, num_classes=3, class_names=None, name='masked_iou_per_class', **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.num_classes = num_classes\n",
    "        self.class_names = class_names or [f'class_{i}' for i in range(num_classes)]\n",
    "        \n",
    "        # Matriz de confusi√≥n acumulativa\n",
    "        self.total_cm = self.add_weight(\n",
    "            name='total_confusion_matrix',\n",
    "            shape=(num_classes, num_classes),\n",
    "            initializer='zeros',\n",
    "            dtype=tf.float32\n",
    "        )\n",
    "    \n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true = tf.squeeze(y_true, axis=-1)\n",
    "        y_pred = tf.argmax(y_pred, axis=-1)\n",
    "        \n",
    "        # Convertir a int32\n",
    "        y_true = tf.cast(y_true, tf.int32)\n",
    "        y_pred = tf.cast(y_pred, tf.int32)\n",
    "        \n",
    "        # M√°scara para ignorar 255\n",
    "        mask = tf.not_equal(y_true, 255)\n",
    "        \n",
    "        # Aplicar m√°scara\n",
    "        y_true = tf.boolean_mask(y_true, mask)\n",
    "        y_pred = tf.boolean_mask(y_pred, mask)\n",
    "        \n",
    "        # Calcular confusion matrix\n",
    "        current_cm = tf.math.confusion_matrix(\n",
    "            y_true,\n",
    "            y_pred,\n",
    "            num_classes=self.num_classes,\n",
    "            dtype=tf.float32\n",
    "        )\n",
    "        \n",
    "        self.total_cm.assign_add(current_cm)\n",
    "    \n",
    "    def result(self):\n",
    "        \"\"\"Retorna el mIoU promedio (para compatibilidad con callbacks)\"\"\"\n",
    "        iou_per_class = self._compute_iou_per_class()\n",
    "        return tf.reduce_mean(iou_per_class)\n",
    "    \n",
    "    def _compute_iou_per_class(self):\n",
    "        \"\"\"Calcula IoU para cada clase\"\"\"\n",
    "        sum_over_row = tf.reduce_sum(self.total_cm, axis=0)  # Predicciones\n",
    "        sum_over_col = tf.reduce_sum(self.total_cm, axis=1)  # Ground truth\n",
    "        diag = tf.linalg.diag_part(self.total_cm)  # True positives\n",
    "        \n",
    "        # IoU = TP / (TP + FP + FN)\n",
    "        denominator = sum_over_row + sum_over_col - diag\n",
    "        \n",
    "        iou = tf.where(\n",
    "            denominator > 0,\n",
    "            diag / denominator,\n",
    "            0.0\n",
    "        )\n",
    "        \n",
    "        return iou\n",
    "    \n",
    "    def get_iou_per_class(self):\n",
    "        \"\"\"M√©todo para obtener IoU por clase (usar despu√©s del entrenamiento)\"\"\"\n",
    "        iou = self._compute_iou_per_class()\n",
    "        return {self.class_names[i]: float(iou[i].numpy()) for i in range(self.num_classes)}\n",
    "    \n",
    "    def reset_state(self):\n",
    "        self.total_cm.assign(tf.zeros_like(self.total_cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5d360329",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedSparseCategoricalAccuracy(tf.keras.metrics.Metric):\n",
    "    def __init__(self, num_classes=3, class_names=None, name='masked_acc', **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.num_classes = num_classes\n",
    "        self.class_names = class_names or [f'class_{i}' for i in range(num_classes)]\n",
    "        \n",
    "        # Acumuladores globales\n",
    "        self.total_correct = self.add_weight(name='total_correct', initializer='zeros', dtype=tf.float32)\n",
    "        self.total_pixels = self.add_weight(name='total_pixels', initializer='zeros', dtype=tf.float32)\n",
    "        \n",
    "        # Acumuladores por clase\n",
    "        self.correct_per_class = self.add_weight(\n",
    "            name='correct_per_class',\n",
    "            shape=(num_classes,),\n",
    "            initializer='zeros',\n",
    "            dtype=tf.float32\n",
    "        )\n",
    "        self.pixels_per_class = self.add_weight(\n",
    "            name='pixels_per_class',\n",
    "            shape=(num_classes,),\n",
    "            initializer='zeros',\n",
    "            dtype=tf.float32\n",
    "        )\n",
    "    \n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true = tf.squeeze(y_true, axis=-1)\n",
    "        y_pred = tf.argmax(y_pred, axis=-1)\n",
    "        \n",
    "        # Convertir a int32\n",
    "        y_true = tf.cast(y_true, tf.int32)\n",
    "        y_pred = tf.cast(y_pred, tf.int32)\n",
    "        \n",
    "        # M√°scara para ignorar 255\n",
    "        mask = tf.not_equal(y_true, 255)\n",
    "        \n",
    "        # Aplicar m√°scara\n",
    "        y_true_masked = tf.boolean_mask(y_true, mask)\n",
    "        y_pred_masked = tf.boolean_mask(y_pred, mask)\n",
    "        \n",
    "        # Accuracy global\n",
    "        correct = tf.cast(tf.equal(y_true_masked, y_pred_masked), tf.float32)\n",
    "        self.total_correct.assign_add(tf.reduce_sum(correct))\n",
    "        self.total_pixels.assign_add(tf.cast(tf.size(y_true_masked), tf.float32))\n",
    "        \n",
    "        # Accuracy por clase\n",
    "        for class_id in range(self.num_classes):\n",
    "            # M√°scara para la clase actual\n",
    "            class_mask = tf.equal(y_true_masked, class_id)\n",
    "            \n",
    "            if tf.reduce_any(class_mask):\n",
    "                y_true_class = tf.boolean_mask(y_true_masked, class_mask)\n",
    "                y_pred_class = tf.boolean_mask(y_pred_masked, class_mask)\n",
    "                \n",
    "                correct_class = tf.cast(tf.equal(y_true_class, y_pred_class), tf.float32)\n",
    "                \n",
    "                # Actualizar acumuladores\n",
    "                self.correct_per_class.scatter_add(\n",
    "                    tf.IndexedSlices(tf.reduce_sum(correct_class), [class_id])\n",
    "                )\n",
    "                self.pixels_per_class.scatter_add(\n",
    "                    tf.IndexedSlices(tf.cast(tf.size(y_true_class), tf.float32), [class_id])\n",
    "                )\n",
    "    \n",
    "    def result(self):\n",
    "        \"\"\"Retorna accuracy global (para compatibilidad con callbacks)\"\"\"\n",
    "        return self.total_correct / tf.maximum(self.total_pixels, 1.0)\n",
    "    \n",
    "    def get_accuracy_per_class(self):\n",
    "        \"\"\"Obtiene accuracy por clase\"\"\"\n",
    "        acc_per_class = tf.where(\n",
    "            self.pixels_per_class > 0,\n",
    "            self.correct_per_class / self.pixels_per_class,\n",
    "            0.0\n",
    "        )\n",
    "        return {self.class_names[i]: float(acc_per_class[i].numpy()) for i in range(self.num_classes)}\n",
    "    \n",
    "    def reset_state(self):\n",
    "        self.total_correct.assign(0.0)\n",
    "        self.total_pixels.assign(0.0)\n",
    "        self.correct_per_class.assign(tf.zeros((self.num_classes,)))\n",
    "        self.pixels_per_class.assign(tf.zeros((self.num_classes,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "da3bdeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "\n",
    "BACKBONE = 'resnet34'#efficientnetb0 tmb puede ser (buena con imag satelitales)\n",
    "model = sm.Unet(\n",
    "    backbone_name=BACKBONE,\n",
    "    encoder_weights='imagenet',\n",
    "    classes=3,\n",
    "    activation='softmax'\n",
    "    #input_shape=(512, 512, 4)\n",
    ")\n",
    "\n",
    "# Definir nombres de clases\n",
    "class_names = ['background', 'road', 'building']\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(1e-4),\n",
    "    loss=masked_sparse_cce,\n",
    "    metrics=[\n",
    "        MaskedSparseCategoricalAccuracy(num_classes=3, class_names=class_names, name='acc'),\n",
    "        MaskedIoUPerClass(num_classes=3, class_names=class_names, name='miou')\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a1433e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrintMetricsPerClass(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, metric_names=['acc', 'miou']):\n",
    "        super().__init__()\n",
    "        self.metric_names = metric_names\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print(f\"\\nüìä √âpoca {epoch+1} - M√©tricas por clase:\")\n",
    "        \n",
    "        for metric in self.model.metrics:\n",
    "            if metric.name in self.metric_names:\n",
    "                if hasattr(metric, 'get_accuracy_per_class'):\n",
    "                    results = metric.get_accuracy_per_class()\n",
    "                    print(f\"\\n  Accuracy por clase:\")\n",
    "                    for class_name, value in results.items():\n",
    "                        print(f\"    {class_name}: {value:.4f}\")\n",
    "                \n",
    "                elif hasattr(metric, 'get_iou_per_class'):\n",
    "                    results = metric.get_iou_per_class()\n",
    "                    print(f\"\\n  IoU por clase:\")\n",
    "                    for class_name, value in results.items():\n",
    "                        print(f\"    {class_name}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "78d6dd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "# Early stopping: detener cuando el modelo deje de mejorar\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',      # m√©trica que se eval√∫a\n",
    "    mode='min',           # porque cuanto m√°s alto, mejor\n",
    "    patience=10,\n",
    "    restore_best_weights=True,\n",
    "    verbose= 1\n",
    ")\n",
    "\n",
    "# Guardar el mejor modelo autom√°ticamente\n",
    "checkpoint = ModelCheckpoint(\n",
    "    r\"checkpoint.keras\",         # ruta del archivo\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=5,\n",
    "    min_lr=1e-7,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80cc860",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=100,\n",
    "    verbose=1,\n",
    "    callbacks=[early_stop, checkpoint, reduce_lr, PrintMetricsPerClass()]\n",
    ")\n",
    "print(\"Epochs realizadas:\", len(history.history['loss']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255a90fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Despu√©s del entrenamiento, obtener IoU por clase\n",
    "iou_metric = model.metrics[-1]  # √öltima m√©trica\n",
    "iou_per_class = iou_metric.get_iou_per_class()\n",
    "\n",
    "print(\"\\nüìä IoU por clase:\")\n",
    "for class_name, iou_value in iou_per_class.items():\n",
    "    print(f\"  {class_name}: {iou_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3f6419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final model\n",
    "model.save(\"model_final.keras\")\n",
    "\n",
    "# Evaluate on train set\n",
    "print(\"\\n=== Evaluaci√≥n en test set ===\")\n",
    "train_results = model.evaluate(train_gen, verbose=1)\n",
    "print(f\"Train Loss: {train_results[0]:.4f}\")\n",
    "print(f\"Train Masked Accuracy: {train_results[1]:.4f}\")\n",
    "print(f\"Train Masked Mean IoU: {train_results[2]:.4f}\")\n",
    "# Evaluate on test set\n",
    "print(\"\\n=== Evaluaci√≥n en val set ===\")\n",
    "val_results = model.evaluate(val_gen, verbose=1)\n",
    "print(f\"Val Loss: {val_results[0]:.4f}\")\n",
    "print(f\"Val Masked Accuracy: {val_results[1]:.4f}\")\n",
    "print(f\"Val Masked Mean IoU: {val_results[2]:.4f}\")\n",
    "# Evaluate on test set\n",
    "print(\"\\n=== Evaluaci√≥n en test set ===\")\n",
    "test_results = model.evaluate(test_gen, verbose=1)\n",
    "print(f\"Test Loss: {test_results[0]:.4f}\")\n",
    "print(f\"Test Masked Accuracy: {test_results[1]:.4f}\")\n",
    "print(f\"Test Masked Mean IoU: {test_results[2]:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
