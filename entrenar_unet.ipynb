{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3ce8d76",
   "metadata": {},
   "source": [
    "### Creación de gpkg de division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4109502e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0929a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Píxeles válidos totales: 588882000\n",
      "Val   asignado: 94217200 (16.0%)\n",
      "Test asignado: 70662900 (12.0%)\n",
      "Train: 424001900\n",
      "Píxeles válidos totales: 591685632\n",
      "Val   asignado: 118332209 (20.0%)\n",
      "Test asignado: 70996459 (12.0%)\n",
      "Train: 402356964\n"
     ]
    }
   ],
   "source": [
    "from utils_pre_procesamiento import generar_tiles_spatial_split\n",
    "\n",
    "tif_sierra = os.getenv('TIF_SIERRA')\n",
    "out_dir_sierra = r\"D:\\Diciembre\\Entrenamiento\\training_road_model\\CapasSierra\"\n",
    "\n",
    "tif_selva = os.getenv('TIF_SELVA')\n",
    "out_dir_selva = r\"D:\\Diciembre\\Entrenamiento\\training_road_model\\CapasSelva\"\n",
    "\n",
    "generar_tiles_spatial_split(tif_sierra, out_dir = out_dir_sierra)\n",
    "generar_tiles_spatial_split(tif_selva, out_dir = out_dir_selva)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5102f70",
   "metadata": {},
   "source": [
    "### Creacion de parches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106d62fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leyendo raster entero para calcular percentiles para posterior normalización de parches\n",
      "Cargando raster...\n",
      "Cargando geometrías...\n",
      "Geometria de : Casas\n",
      "Geometria de : Caminos\n",
      "Geometria de : Area fuera de interes\n",
      "Cargando tiles...\n",
      "\n",
      "Procesando tile 0 → train\n",
      "\n",
      "Procesando tile 1 → train\n",
      "\n",
      "Procesando tile 2 → val\n",
      "\n",
      "Procesando tile 3 → train\n",
      "\n",
      "Procesando tile 4 → train\n",
      "\n",
      "Procesando tile 5 → train\n",
      "\n",
      "Procesando tile 6 → train\n",
      "\n",
      "Procesando tile 7 → train\n",
      "\n",
      "Procesando tile 8 → test\n",
      "\n",
      "Procesando tile 9 → train\n",
      "\n",
      "Procesando tile 10 → val\n",
      "\n",
      "Procesando tile 11 → train\n",
      "\n",
      "Procesando tile 12 → val\n",
      "\n",
      "Procesando tile 13 → train\n",
      "\n",
      "Procesando tile 14 → train\n",
      "\n",
      "Procesando tile 15 → train\n",
      "\n",
      "Procesando tile 16 → train\n",
      "\n",
      "Procesando tile 17 → train\n",
      "\n",
      "Procesando tile 18 → test\n",
      "\n",
      "Procesando tile 19 → train\n",
      "\n",
      "Procesando tile 20 → val\n",
      "\n",
      "Procesando tile 21 → test\n",
      "\n",
      "Procesando tile 22 → val\n",
      "\n",
      "Procesando tile 23 → train\n",
      "\n",
      "Procesando tile 24 → train\n",
      "\n",
      " LISTO: Dataset generado correctamente.\n",
      "Total de parches generados: 002705_006024\n",
      "Leyendo raster entero para calcular percentiles para posterior normalización de parches\n",
      "Cargando raster...\n",
      "Cargando geometrías...\n",
      "Geometria de : Casas\n",
      "Geometria de : Caminos\n",
      "Cargando tiles...\n",
      "\n",
      "Procesando tile 0 → val\n",
      "\n",
      "Procesando tile 1 → test\n",
      "\n",
      "Procesando tile 2 → val\n",
      "\n",
      "Procesando tile 3 → train\n",
      "\n",
      "Procesando tile 4 → val\n",
      "\n",
      "Procesando tile 5 → train\n",
      "\n",
      "Procesando tile 6 → train\n",
      "\n",
      "Procesando tile 7 → train\n",
      "\n",
      "Procesando tile 8 → train\n",
      "\n",
      "Procesando tile 9 → train\n",
      "\n",
      "Procesando tile 10 → test\n",
      "\n",
      "Procesando tile 11 → val\n",
      "\n",
      "Procesando tile 12 → train\n",
      "\n",
      "Procesando tile 13 → train\n",
      "\n",
      "Procesando tile 14 → train\n",
      "\n",
      "Procesando tile 15 → train\n",
      "\n",
      "Procesando tile 16 → train\n",
      "\n",
      "Procesando tile 17 → test\n",
      "\n",
      "Procesando tile 18 → train\n",
      "\n",
      "Procesando tile 19 → val\n",
      "\n",
      "Procesando tile 20 → val\n",
      "\n",
      "Procesando tile 21 → train\n",
      "\n",
      "Procesando tile 22 → train\n",
      "\n",
      "Procesando tile 23 → train\n",
      "\n",
      "Procesando tile 24 → train\n",
      "\n",
      " LISTO: Dataset generado correctamente.\n",
      "Total de parches generados: 010438_002418\n"
     ]
    }
   ],
   "source": [
    "from raster_to_tile import data_split\n",
    "\n",
    "tif_selva = r\"D:\\Shapefiles\\PI\\CO_2512022106159\\VOL_PER1_ORT_001_010438\\IMG_PER1_ORT_PMS_010438\\IMG_PER1_20230922151914_ORT_PMS_010438.TIF\"\n",
    "tif_sierra = r\"D:\\Shapefiles\\PI\\CO_2510221339013\\VOL_PER1_ORT_001_002705\\IMG_PER1_ORT_PMS_002705\\IMG_PER1_20210706153514_ORT_PMS_002705.TIF\"\n",
    "\n",
    "mask_casas_selva_path = r\"D:\\Diciembre\\Entrenamiento\\training_road_model\\CapasSelva\\buildings_32718_selva.gpkg\"\n",
    "mask_casas_sierra_path = r\"D:\\Diciembre\\Entrenamiento\\training_road_model\\CapasSierra\\buildings_32717_sierra.gpkg\"\n",
    "\n",
    "mask_caminos_selva_path = r\"D:\\Diciembre\\Entrenamiento\\training_road_model\\CapasSelva\\capa_carreteras_selva.gpkg\"\n",
    "mask_caminos_sierra_path = r\"D:\\Diciembre\\Entrenamiento\\training_road_model\\CapasSierra\\capa_carreteras_sierra.gpkg\"\n",
    "\n",
    "gpkg_division_selva_tile = r\"D:\\Diciembre\\Entrenamiento\\training_road_model\\CapasSelva\\division_en_tile_010438.gpkg\"\n",
    "gpkg_division_sierra_tile = r\"D:\\Diciembre\\Entrenamiento\\training_road_model\\CapasSierra\\division_en_tile_002705.gpkg\"\n",
    "\n",
    "dataset_general_out = r\"D:\\Diciembre\\Entrenamiento\\training_road_model\\Dataset\"\n",
    "\n",
    "### Area Excluida\n",
    "gpkg_area_ciudad = r\"D:\\Diciembre\\Entrenamiento\\training_road_model\\CapasSierra\\area_excluida_sierra.gpkg\"\n",
    "\n",
    "#Sierra\n",
    "data_split(tif_sierra, mask_casas_sierra_path, mask_caminos_sierra_path, gpkg_division_sierra_tile, dataset_general_out, gpkg_area_excluida_path=gpkg_area_ciudad)\n",
    "#Selva\n",
    "data_split(tif_selva, mask_casas_selva_path, mask_caminos_selva_path, gpkg_division_selva_tile, dataset_general_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5762ec",
   "metadata": {},
   "source": [
    "### Verificar GPU disponible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba486f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version: 2.10.1\n",
      "Built with CUDA: True\n",
      "GPUs: []\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"TF version:\", tf.__version__)\n",
    "print(\"Built with CUDA:\", tf.test.is_built_with_cuda())\n",
    "print(\"GPUs:\", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3d6a780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "División correcta sin errores de archivos.\n",
      "--------------------------------------------------\n",
      "TRAIN     → imágenes: 5919 | máscaras: 5917\n",
      "VALIDATION → imágenes: 1518 | máscaras: 1517\n",
      "TEST      → imágenes: 1008 | máscaras: 1008\n",
      "--------------------------------------------------\n",
      "TOTAL IMGS: 8445\n",
      "TOTAL MASKS: 8442\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from utils2 import split_dataset\n",
    "\n",
    "(train_imgs, train_masks, val_imgs, val_masks, test_imgs, test_masks) = split_dataset(carpeta=r\"D:\\Diciembre\\Entrenamiento\\training_road_model\\Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd7bab74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\prac-dnce\\miniconda3\\envs\\tf\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\prac-dnce\\miniconda3\\envs\\tf\\lib\\site-packages\\albumentations\\core\\validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
      "  original_init(self, **validated_kwargs)\n",
      "d:\\Diciembre\\Entrenamiento\\Unet\\TiffDataGeneratorAugmentedUnet.py:49: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
      "  A.GaussNoise(var_limit=(3, 10), p=0.1)\n"
     ]
    }
   ],
   "source": [
    "from TiffDataGeneratorAugmentedUnet import TIFFDataGeneratorAug\n",
    "\n",
    "# Generadores\n",
    "train_gen = TIFFDataGeneratorAug(train_imgs, train_masks, normalize='imagenet',batch_size=1, n_channels=3, augment=True)#<--- canales\n",
    "val_gen = TIFFDataGeneratorAug(val_imgs, val_masks, normalize='imagenet', batch_size=1, shuffle=False, n_channels=3, augment=False)#<--- canales\n",
    "test_gen = TIFFDataGeneratorAug(test_imgs, test_masks, normalize='imagenet', batch_size=1, shuffle=False, n_channels=3, augment=False)#<--- canales\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d86c3203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation Models: using `tf.keras` framework.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"SM_FRAMEWORK\"] = \"tf.keras\"\n",
    "\n",
    "from tensorflow import keras\n",
    "import segmentation_models as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da3bdeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "import configuraciones as cfg\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "BACKBONE = 'resnet34'#efficientnetb0 tmb puede ser (buena con imag satelitales)\n",
    "model = sm.Unet(\n",
    "    backbone_name=BACKBONE,\n",
    "    encoder_weights='imagenet',\n",
    "    classes=3,\n",
    "    activation='softmax'\n",
    "    #input_shape=(512, 512, 4)\n",
    ")\n",
    "\n",
    "# Definir nombres de clases\n",
    "class_names = ['background', 'road', 'building']\n",
    "\n",
    "# Crear métricas ANTES (para tener referencia)\n",
    "acc_metric = cfg.MaskedSparseCategoricalAccuracy(\n",
    "    num_classes=3, \n",
    "    class_names=class_names, \n",
    "    name='acc'\n",
    ")\n",
    "\n",
    "iou_metric = cfg.MeanIoUPerClass(\n",
    "    num_classes=3, \n",
    "    class_names=class_names, \n",
    "    name='miou'\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(1e-4),\n",
    "    loss=cfg.masked_sparse_cce,\n",
    "    metrics=[\n",
    "        acc_metric,\n",
    "        iou_metric\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78d6dd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',      # métrica que se evalúa\n",
    "    mode='min',\n",
    "    patience=10,\n",
    "    restore_best_weights=True,\n",
    "    verbose= 1\n",
    ")\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    r\"checkpoint.keras\",         # ruta del archivo\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau( # reduccion lr auto\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=5,\n",
    "    min_lr=1e-7,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "metrics_callback = cfg.PrintMetricsPerClass([acc_metric,iou_metric])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be46cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc\n",
      "miou\n"
     ]
    }
   ],
   "source": [
    "all_metrics = model.compiled_metrics._metrics  # Esto es una lista\n",
    "for metric in all_metrics:  # Iterar sobre cada elemento\n",
    "    print(metric.name)  # Ahora metric es un objeto con atributo 'name'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80cc860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "  15/5919 [..............................] - ETA: 1:59:06 - loss: 1.3716 - acc: 0.3080 - miou: 0.1073"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_gen\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_gen\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce_lr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPrintMetricsPerClass\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43macc_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43miou_metric\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpochs realizadas:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n",
      "File \u001b[1;32mc:\\Users\\prac-dnce\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\prac-dnce\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\prac-dnce\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\prac-dnce\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\prac-dnce\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\prac-dnce\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\prac-dnce\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\prac-dnce\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\prac-dnce\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=100,\n",
    "    verbose=1,\n",
    "    callbacks=[early_stop, checkpoint, reduce_lr, cfg.PrintMetricsPerClass()]\n",
    ")\n",
    "print(\"Epochs realizadas:\", len(history.history['loss']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255a90fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Después del entrenamiento, obtener IoU por clase\n",
    "iou_metric = model.metrics[-1]  # Última métrica\n",
    "iou_per_class = iou_metric.get_iou_per_class()\n",
    "\n",
    "print(\"\\nIoU por clase:\")\n",
    "for class_name, iou_value in iou_per_class.items():\n",
    "    print(f\"  {class_name}: {iou_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3f6419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final model\n",
    "model.save(\"model_final.keras\")\n",
    "\n",
    "# Evaluate on train set\n",
    "print(\"\\n=== Evaluación en test set ===\")\n",
    "train_results = model.evaluate(train_gen, verbose=1)\n",
    "print(f\"Train Loss: {train_results[0]:.4f}\")\n",
    "print(f\"Train Masked Accuracy: {train_results[1]:.4f}\")\n",
    "print(f\"Train Masked Mean IoU: {train_results[2]:.4f}\")\n",
    "# Evaluate on test set\n",
    "print(\"\\n=== Evaluación en val set ===\")\n",
    "val_results = model.evaluate(val_gen, verbose=1)\n",
    "print(f\"Val Loss: {val_results[0]:.4f}\")\n",
    "print(f\"Val Masked Accuracy: {val_results[1]:.4f}\")\n",
    "print(f\"Val Masked Mean IoU: {val_results[2]:.4f}\")\n",
    "# Evaluate on test set\n",
    "print(\"\\n=== Evaluación en test set ===\")\n",
    "test_results = model.evaluate(test_gen, verbose=1)\n",
    "print(f\"Test Loss: {test_results[0]:.4f}\")\n",
    "print(f\"Test Masked Accuracy: {test_results[1]:.4f}\")\n",
    "print(f\"Test Masked Mean IoU: {test_results[2]:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
