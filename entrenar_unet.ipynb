{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "106d62fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leyendo raster entero para calcular percentiles para posterior normalización de parches\n",
      "Cargando raster...\n",
      "Cargando geometrías...\n",
      "Geometria de : Casas\n",
      "Geometria de : Caminos\n",
      "Geometria de : Area fuera de interes\n",
      "Cargando tiles...\n",
      "\n",
      "Procesando tile 0 → train\n",
      "\n",
      "Procesando tile 1 → test\n",
      "\n",
      "Procesando tile 2 → train\n",
      "\n",
      "Procesando tile 3 → val\n",
      "\n",
      "Procesando tile 4 → train\n",
      "\n",
      "Procesando tile 5 → val\n",
      "\n",
      "Procesando tile 6 → train\n",
      "\n",
      "Procesando tile 7 → train\n",
      "\n",
      "Procesando tile 8 → train\n",
      "\n",
      "Procesando tile 9 → train\n",
      "\n",
      "Procesando tile 10 → train\n",
      "\n",
      "Procesando tile 11 → test\n",
      "\n",
      "Procesando tile 12 → train\n",
      "Se excluyo el tile: 3064\n",
      "Se excluyo el tile: 3081\n",
      "Se excluyo el tile: 3081\n",
      "Se excluyo el tile: 3098\n",
      "Se excluyo el tile: 3098\n",
      "Se excluyo el tile: 3115\n",
      "Se excluyo el tile: 3115\n",
      "Se excluyo el tile: 3132\n",
      "Se excluyo el tile: 3132\n",
      "Se excluyo el tile: 3149\n",
      "Se excluyo el tile: 3149\n",
      "Se excluyo el tile: 3166\n",
      "Se excluyo el tile: 3166\n",
      "Se excluyo el tile: 3183\n",
      "Se excluyo el tile: 3183\n",
      "Se excluyo el tile: 3200\n",
      "Se excluyo el tile: 3200\n",
      "Se excluyo el tile: 3217\n",
      "Se excluyo el tile: 3217\n",
      "Se excluyo el tile: 3235\n",
      "\n",
      "Procesando tile 13 → val\n",
      "Se excluyo el tile: 3341\n",
      "Se excluyo el tile: 3359\n",
      "Se excluyo el tile: 3359\n",
      "Se excluyo el tile: 3365\n",
      "Se excluyo el tile: 3374\n",
      "Se excluyo el tile: 3374\n",
      "Se excluyo el tile: 3374\n",
      "Se excluyo el tile: 3380\n",
      "Se excluyo el tile: 3380\n",
      "Se excluyo el tile: 3380\n",
      "Se excluyo el tile: 3387\n",
      "Se excluyo el tile: 3387\n",
      "Se excluyo el tile: 3387\n",
      "Se excluyo el tile: 3393\n",
      "Se excluyo el tile: 3393\n",
      "Se excluyo el tile: 3393\n",
      "Se excluyo el tile: 3393\n",
      "Se excluyo el tile: 3393\n",
      "Se excluyo el tile: 3398\n",
      "Se excluyo el tile: 3398\n",
      "Se excluyo el tile: 3398\n",
      "Se excluyo el tile: 3404\n",
      "Se excluyo el tile: 3404\n",
      "Se excluyo el tile: 3404\n",
      "Se excluyo el tile: 3404\n",
      "Se excluyo el tile: 3404\n",
      "Se excluyo el tile: 3404\n",
      "Se excluyo el tile: 3408\n",
      "Se excluyo el tile: 3408\n",
      "Se excluyo el tile: 3415\n",
      "Se excluyo el tile: 3415\n",
      "Se excluyo el tile: 3415\n",
      "Se excluyo el tile: 3415\n",
      "Se excluyo el tile: 3415\n",
      "Se excluyo el tile: 3415\n",
      "Se excluyo el tile: 3415\n",
      "Se excluyo el tile: 3417\n",
      "Se excluyo el tile: 3417\n",
      "Se excluyo el tile: 3417\n",
      "Se excluyo el tile: 3424\n",
      "Se excluyo el tile: 3424\n",
      "Se excluyo el tile: 3424\n",
      "Se excluyo el tile: 3424\n",
      "Se excluyo el tile: 3424\n",
      "Se excluyo el tile: 3424\n",
      "Se excluyo el tile: 3424\n",
      "Se excluyo el tile: 3424\n",
      "Se excluyo el tile: 3424\n",
      "Se excluyo el tile: 3424\n",
      "Se excluyo el tile: 3424\n",
      "Se excluyo el tile: 3424\n",
      "Se excluyo el tile: 3431\n",
      "Se excluyo el tile: 3431\n",
      "Se excluyo el tile: 3431\n",
      "Se excluyo el tile: 3431\n",
      "Se excluyo el tile: 3431\n",
      "Se excluyo el tile: 3431\n",
      "Se excluyo el tile: 3431\n",
      "Se excluyo el tile: 3431\n",
      "Se excluyo el tile: 3431\n",
      "Se excluyo el tile: 3431\n",
      "Se excluyo el tile: 3431\n",
      "Se excluyo el tile: 3431\n",
      "Se excluyo el tile: 3438\n",
      "Se excluyo el tile: 3438\n",
      "Se excluyo el tile: 3438\n",
      "Se excluyo el tile: 3438\n",
      "Se excluyo el tile: 3438\n",
      "Se excluyo el tile: 3438\n",
      "Se excluyo el tile: 3438\n",
      "Se excluyo el tile: 3438\n",
      "Se excluyo el tile: 3438\n",
      "Se excluyo el tile: 3438\n",
      "Se excluyo el tile: 3438\n",
      "Se excluyo el tile: 3438\n",
      "Se excluyo el tile: 3445\n",
      "Se excluyo el tile: 3445\n",
      "Se excluyo el tile: 3445\n",
      "Se excluyo el tile: 3445\n",
      "Se excluyo el tile: 3445\n",
      "Se excluyo el tile: 3445\n",
      "Se excluyo el tile: 3445\n",
      "Se excluyo el tile: 3445\n",
      "Se excluyo el tile: 3445\n",
      "Se excluyo el tile: 3445\n",
      "Se excluyo el tile: 3445\n",
      "Se excluyo el tile: 3453\n",
      "Se excluyo el tile: 3453\n",
      "Se excluyo el tile: 3453\n",
      "Se excluyo el tile: 3453\n",
      "Se excluyo el tile: 3453\n",
      "Se excluyo el tile: 3453\n",
      "Se excluyo el tile: 3453\n",
      "Se excluyo el tile: 3453\n",
      "Se excluyo el tile: 3453\n",
      "Se excluyo el tile: 3453\n",
      "Se excluyo el tile: 3453\n",
      "Se excluyo el tile: 3461\n",
      "Se excluyo el tile: 3461\n",
      "Se excluyo el tile: 3461\n",
      "Se excluyo el tile: 3461\n",
      "Se excluyo el tile: 3461\n",
      "Se excluyo el tile: 3461\n",
      "Se excluyo el tile: 3461\n",
      "Se excluyo el tile: 3461\n",
      "Se excluyo el tile: 3461\n",
      "Se excluyo el tile: 3461\n",
      "Se excluyo el tile: 3470\n",
      "Se excluyo el tile: 3470\n",
      "Se excluyo el tile: 3470\n",
      "Se excluyo el tile: 3470\n",
      "Se excluyo el tile: 3470\n",
      "Se excluyo el tile: 3470\n",
      "Se excluyo el tile: 3470\n",
      "Se excluyo el tile: 3470\n",
      "Se excluyo el tile: 3470\n",
      "Se excluyo el tile: 3470\n",
      "\n",
      "Procesando tile 14 → train\n",
      "\n",
      "Procesando tile 15 → val\n",
      "\n",
      "Procesando tile 16 → train\n",
      "\n",
      "Procesando tile 17 → train\n",
      "\n",
      "Procesando tile 18 → test\n",
      "Se excluyo el tile: 4701\n",
      "Se excluyo el tile: 4701\n",
      "Se excluyo el tile: 4701\n",
      "Se excluyo el tile: 4701\n",
      "Se excluyo el tile: 4701\n",
      "Se excluyo el tile: 4701\n",
      "Se excluyo el tile: 4701\n",
      "Se excluyo el tile: 4701\n",
      "Se excluyo el tile: 4701\n",
      "Se excluyo el tile: 4701\n",
      "Se excluyo el tile: 4712\n",
      "Se excluyo el tile: 4712\n",
      "Se excluyo el tile: 4712\n",
      "Se excluyo el tile: 4712\n",
      "Se excluyo el tile: 4712\n",
      "Se excluyo el tile: 4712\n",
      "Se excluyo el tile: 4712\n",
      "Se excluyo el tile: 4712\n",
      "Se excluyo el tile: 4724\n",
      "Se excluyo el tile: 4724\n",
      "Se excluyo el tile: 4724\n",
      "Se excluyo el tile: 4724\n",
      "Se excluyo el tile: 4724\n",
      "Se excluyo el tile: 4724\n",
      "Se excluyo el tile: 4724\n",
      "Se excluyo el tile: 4738\n",
      "Se excluyo el tile: 4738\n",
      "Se excluyo el tile: 4738\n",
      "Se excluyo el tile: 4738\n",
      "Se excluyo el tile: 4738\n",
      "Se excluyo el tile: 4755\n",
      "\n",
      "Procesando tile 19 → train\n",
      "\n",
      "Procesando tile 20 → train\n",
      "\n",
      "Procesando tile 21 → train\n",
      "\n",
      "Procesando tile 22 → train\n",
      "\n",
      "Procesando tile 23 → train\n",
      "\n",
      "Procesando tile 24 → val\n",
      "\n",
      " LISTO: Dataset generado correctamente.\n",
      "Total de parches generados: 6020\n"
     ]
    }
   ],
   "source": [
    "from raster_to_tile import data_split\n",
    "\n",
    "tif_selva = r\"D:\\Shapefiles\\PI\\CO_2512022106159\\VOL_PER1_ORT_001_010438\\IMG_PER1_ORT_PMS_010438\\IMG_PER1_20230922151914_ORT_PMS_010438.TIF\"\n",
    "tif_sierra = r\"D:\\Shapefiles\\PI\\CO_2510221339013\\VOL_PER1_ORT_001_002705\\IMG_PER1_ORT_PMS_002705\\IMG_PER1_20210706153514_ORT_PMS_002705.TIF\"\n",
    "\n",
    "mask_casas_selva_path = r\"D:\\Diciembre\\Entrenamiento\\training_road_model\\CapasSelva\\buildings_32718_selva.gpkg\"\n",
    "mask_casas_sierra_path = r\"D:\\Diciembre\\Entrenamiento\\training_road_model\\CapasSierra\\buildings_32717_sierra.gpkg\"\n",
    "\n",
    "mask_caminos_selva_path = r\"D:\\Diciembre\\Entrenamiento\\training_road_model\\CapasSelva\\capa_carreteras_selva.gpkg\"\n",
    "mask_caminos_sierra_path = r\"D:\\Diciembre\\Entrenamiento\\training_road_model\\CapasSierra\\\\capa_carreteras_sierra.gpkg\"\n",
    "\n",
    "gpkg_division_selva_tile = r\"D:\\Diciembre\\Entrenamiento\\training_road_model\\CapasSelva\\division_en_tile_selva.gpkg\"\n",
    "gpkg_division_sierra_tile = r\"D:\\Diciembre\\Entrenamiento\\training_road_model\\CapasSierra\\division_en_tile_sierra.gpkg\"\n",
    "\n",
    "dataset_selva_path = r\"D:\\Diciembre\\Entrenamiento\\training_road_model\\DatasetSelvaMulticlase\"\n",
    "dataset_sierra_path = r\"D:\\Diciembre\\Entrenamiento\\training_road_model\\DatasetSierraMulticlase1\"\n",
    "\n",
    "### Area Excluida\n",
    "gpkg_area_ciudad = r\"D:\\Diciembre\\Entrenamiento\\training_road_model\\CapasSierra\\area_excluida_sierra.gpkg\"\n",
    "\n",
    "data_split(tif_sierra, mask_casas_sierra_path, mask_caminos_sierra_path, gpkg_division_sierra_tile, dataset_sierra_path, gpkg_area_excluida_path=gpkg_area_ciudad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "464846c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs disponibles: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(\"GPUs disponibles:\", gpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3d6a780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "División correcta sin errores de archivos.\n",
      "--------------------------------------------------\n",
      "TRAIN     → imágenes: 4117 | máscaras: 4117\n",
      "VALIDATION → imágenes: 938 | máscaras: 938\n",
      "TEST      → imágenes: 969 | máscaras: 969\n",
      "--------------------------------------------------\n",
      "TOTAL IMGS: 6024\n",
      "TOTAL MASKS: 6024\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from utils2 import split_dataset\n",
    "dataset_path = r\"D:\\Diciembre\\Entrenamiento\\training_road_model\\DatasetSierraMulticlase\"\n",
    "\n",
    "(train_imgs, train_masks, val_imgs, val_masks, test_imgs, test_masks) = split_dataset(carpeta=dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd7bab74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\prac-dnce\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\albumentations\\core\\validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
      "  original_init(self, **validated_kwargs)\n",
      "d:\\Diciembre\\Entrenamiento\\Unet\\TiffDataGeneratorAugmentedUnet.py:49: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
      "  A.GaussNoise(var_limit=(3, 10), p=0.1)\n"
     ]
    }
   ],
   "source": [
    "from TiffDataGeneratorAugmentedUnet import TIFFDataGeneratorAug\n",
    "\n",
    "# Generadores\n",
    "train_gen = TIFFDataGeneratorAug(train_imgs, train_masks, normalize='imagenet',batch_size=2, n_channels=3, augment=True)#<--- canales\n",
    "val_gen = TIFFDataGeneratorAug(val_imgs, val_masks, normalize='imagenet', batch_size=2, shuffle=False, n_channels=3, augment=False)#<--- canales\n",
    "test_gen = TIFFDataGeneratorAug(test_imgs, test_masks, normalize='imagenet', batch_size=1, shuffle=False, n_channels=3, augment=False)#<--- canales\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d86c3203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation Models: using `tf.keras` framework.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"SM_FRAMEWORK\"] = \"tf.keras\"\n",
    "\n",
    "from tensorflow import keras\n",
    "import segmentation_models as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3e3d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_sparse_cce(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Sparse categorical crossentropy que ignora píxeles con label 255\n",
    "    \"\"\"\n",
    "    y_true = tf.squeeze(y_true, axis=-1)  # (B,H,W)\n",
    "    \n",
    "    # Crear máscara para píxeles válidos\n",
    "    mask = tf.not_equal(y_true, 255)\n",
    "    mask = tf.cast(mask, tf.float32)\n",
    "    \n",
    "    # Reemplazar 255 con 0 para evitar errores\n",
    "    y_true_safe = tf.where(mask > 0, y_true, 0)\n",
    "    \n",
    "    # Calcular loss por píxel\n",
    "    loss = tf.keras.losses.sparse_categorical_crossentropy(\n",
    "        y_true_safe, y_pred, from_logits=False\n",
    "    )\n",
    "    \n",
    "    # Aplicar máscara y promediar solo sobre píxeles válidos\n",
    "    loss = loss * mask\n",
    "    \n",
    "    # Evitar división por cero\n",
    "    num_valid = tf.maximum(tf.reduce_sum(mask), 1.0)\n",
    "    \n",
    "    return tf.reduce_sum(loss) / num_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb6b3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedMeanIoU(tf.keras.metrics.Metric):\n",
    "    def __init__(self, num_classes=3, name='masked_mean_iou', **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.num_classes = num_classes\n",
    "        self.total_cm = self.add_weight(\n",
    "            name='total_confusion_matrix',\n",
    "            shape=(num_classes, num_classes),\n",
    "            initializer='zeros'\n",
    "        )\n",
    "    \n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true = tf.squeeze(y_true, axis=-1)\n",
    "        y_pred = tf.argmax(y_pred, axis=-1)\n",
    "        \n",
    "        # Convertir a int32 ANTES de crear la máscara\n",
    "        y_true = tf.cast(y_true, tf.int32)\n",
    "        y_pred = tf.cast(y_pred, tf.int32)\n",
    "        \n",
    "        # Máscara para ignorar 255\n",
    "        mask = tf.not_equal(y_true, 255)\n",
    "        \n",
    "        # Aplicar máscara\n",
    "        y_true = tf.boolean_mask(y_true, mask)\n",
    "        y_pred = tf.boolean_mask(y_pred, mask)\n",
    "        \n",
    "        # Calcular confusion matrix\n",
    "        current_cm = tf.math.confusion_matrix(\n",
    "            y_true,\n",
    "            y_pred,\n",
    "            num_classes=self.num_classes,\n",
    "            dtype=tf.float32\n",
    "        )\n",
    "        \n",
    "        self.total_cm.assign_add(current_cm)\n",
    "    \n",
    "    def result(self):\n",
    "        sum_over_row = tf.reduce_sum(self.total_cm, axis=0)\n",
    "        sum_over_col = tf.reduce_sum(self.total_cm, axis=1)\n",
    "        diag = tf.linalg.diag_part(self.total_cm)\n",
    "        \n",
    "        denominator = sum_over_row + sum_over_col - diag\n",
    "        \n",
    "        iou = tf.where(\n",
    "            denominator > 0,\n",
    "            diag / denominator,\n",
    "            0.0\n",
    "        )\n",
    "        \n",
    "        return tf.reduce_mean(iou)\n",
    "    \n",
    "    def reset_state(self):\n",
    "        self.total_cm.assign(tf.zeros_like(self.total_cm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d360329",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedSparseCategoricalAccuracy(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name='masked_acc', **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.total_correct = self.add_weight(name='total_correct', initializer='zeros')\n",
    "        self.total_pixels = self.add_weight(name='total_pixels', initializer='zeros')\n",
    "    \n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true = tf.squeeze(y_true, axis=-1)\n",
    "        y_pred = tf.argmax(y_pred, axis=-1)\n",
    "        \n",
    "        # Convertir ambos a int32 antes de la máscara\n",
    "        y_true = tf.cast(y_true, tf.int32)\n",
    "        y_pred = tf.cast(y_pred, tf.int32)\n",
    "        \n",
    "        # Máscara para ignorar 255\n",
    "        mask = tf.not_equal(y_true, 255)\n",
    "        \n",
    "        y_true = tf.boolean_mask(y_true, mask)\n",
    "        y_pred = tf.boolean_mask(y_pred, mask)\n",
    "        \n",
    "        correct = tf.cast(tf.equal(y_true, y_pred), tf.float32)\n",
    "        \n",
    "        self.total_correct.assign_add(tf.reduce_sum(correct))\n",
    "        self.total_pixels.assign_add(tf.cast(tf.size(y_true), tf.float32))\n",
    "    \n",
    "    def result(self):\n",
    "        return self.total_correct / tf.maximum(self.total_pixels, 1.0)\n",
    "    \n",
    "    def reset_state(self):\n",
    "        self.total_correct.assign(0.0)\n",
    "        self.total_pixels.assign(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3bdeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "\n",
    "BACKBONE = 'resnet34'#efficientnetb0 tmb puede ser (buena con imag satelitales)\n",
    "model = sm.Unet(\n",
    "    backbone_name=BACKBONE,\n",
    "    encoder_weights='imagenet',\n",
    "    classes=3,\n",
    "    activation='softmax'\n",
    "    #input_shape=(512, 512, 4)\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(1e-4),\n",
    "    loss=masked_sparse_cce,\n",
    "    metrics=[\n",
    "        MaskedSparseCategoricalAccuracy(),\n",
    "        MaskedMeanIoU(num_classes=3)\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d6dd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "# Early stopping: detener cuando el modelo deje de mejorar\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',      # métrica que se evalúa\n",
    "    mode='min',           # porque cuanto más alto, mejor\n",
    "    patience=10,\n",
    "    restore_best_weights=True,\n",
    "    verbose= 1\n",
    ")\n",
    "\n",
    "# Guardar el mejor modelo automáticamente\n",
    "checkpoint = ModelCheckpoint(\n",
    "    r\"D:\\Diciembre\\Entrenamiento\\training_road_model\\Sierra\\Checkpoints\\checkpoint.keras\",         # ruta del archivo\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=5,\n",
    "    min_lr=1e-7,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80cc860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 512, 512, 3)\n",
      "Epoch 1/100\n",
      "(2, 512, 512, 3)\n",
      "(2, 512, 512, 3)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=100,\n",
    "    verbose=1,\n",
    "    callbacks=[early_stop, checkpoint, reduce_lr]\n",
    ")\n",
    "print(\"Epochs realizadas:\", len(history.history['loss']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3f6419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final model\n",
    "model.save(\"model_final.keras\")\n",
    "\n",
    "# Evaluate on train set\n",
    "print(\"\\n=== Evaluación en test set ===\")\n",
    "train_results = model.evaluate(train_gen, verbose=1)\n",
    "print(f\"Train Loss: {train_results[0]:.4f}\")\n",
    "print(f\"Train Masked Accuracy: {train_results[1]:.4f}\")\n",
    "print(f\"Train Masked Mean IoU: {train_results[2]:.4f}\")\n",
    "# Evaluate on test set\n",
    "print(\"\\n=== Evaluación en val set ===\")\n",
    "val_results = model.evaluate(val_gen, verbose=1)\n",
    "print(f\"Val Loss: {val_results[0]:.4f}\")\n",
    "print(f\"Val Masked Accuracy: {val_results[1]:.4f}\")\n",
    "print(f\"Val Masked Mean IoU: {val_results[2]:.4f}\")\n",
    "# Evaluate on test set\n",
    "print(\"\\n=== Evaluación en test set ===\")\n",
    "test_results = model.evaluate(test_gen, verbose=1)\n",
    "print(f\"Test Loss: {test_results[0]:.4f}\")\n",
    "print(f\"Test Masked Accuracy: {test_results[1]:.4f}\")\n",
    "print(f\"Test Masked Mean IoU: {test_results[2]:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
